import os
from datetime import datetime
from urllib.request import urlopen, Request
from urllib.parse import urlparse

UA = "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:64.0) Gecko/20100101 Firefox/64.0"
badurl = [
    'capesandbox.com',
    'pastebin.com',
    '([0-9',
    'paste.cryptolaemus.com',
    'twitter.com',
    'github.com',
    'A-Za-']
pastebin_user = ['jroosen', 'emf1123']

def get_urls(user):
    results = os.popen(
        "curl -A '" +
        UA +
        "' -q https://pastebin.com/u/" +
        user +
        " |grep Emotet |grep \"$(date +\'%Y-%m-%d\')\" |awk '{ print $14 }' |cut -d'\"' -f2-2").read()
    results = results.splitlines()
    if(len(results) > 0):
        print(str(len(results)) + " paste found for " + user +
              " on " + str(datetime.date(datetime.now())))
        return results
    else:
        print("No paste found for " + user + " on " +
              str(datetime.date(datetime.now())))
        return []

def uri_validator(x):
    try:
        result = urlparse(x)
        return all([result.scheme, result.netloc, result.path])
    except BaseException:
        return False

def parse_url(list_urls):
    if(len(list_urls) > 0):
        a = []
        for url in list_urls:
            url = "https://pastebin.com/raw" + url
            try:
                reply = urlopen(
                    Request(
                        url,
                        headers={
                           'User-Agent': UA}),
                    timeout=5)
                b = parse(reply.read().decode("utf8"))
                if(b is not None):
                    for e in b:
                        a.append(e)
            except Exception as e:
                print(e)
                exit(0)
        return a

def parse(content):
    content = content.splitlines()
    item_list = []
    for item in content:
        if("hxxp" in item or "http" in item):
            a_match = [True for match in badurl if match in item]
            item = item.replace("hxxp://", "http://")
            item = item.replace("hxxps://", "https://")
            if True not in a_match and uri_validator(item):
                item_list.append(item)
    return item_list


infected_sites = []

for user in pastebin_user:
    array = parse_url(get_urls(user))
    if(array is not None):
        infected_sites = infected_sites + array

mylist = list(dict.fromkeys(infected_sites))
for x in mylist:
    print(x)
